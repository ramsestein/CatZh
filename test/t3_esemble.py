#!/usr/bin/env python3
"""
Script para crear datasets con ranking semÃ¡ntico de traducciones.

Compara las traducciones de 6 modelos usando embeddings semÃ¡nticos,
rankea por similitud, y crea datasets con los mejores 2 y 3.
"""

import argparse
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Tuple
from tqdm import tqdm
import warnings
from collections import defaultdict, Counter
import torch

# Suprimir warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

class MultiModelSemanticRanker:
    """Rankeador con votaciÃ³n de mÃºltiples modelos de embedding"""
    
    def __init__(self, model_paths: List[str] = None, device: str = "auto"):
        if model_paths is None:
            model_paths = [
                "sentence-transformers/LaBSE",
                "BAAI/bge-large-zh-v1.5", 
                "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
            ]
        
        self.model_paths = model_paths
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu") if device == "auto" else torch.device(device)
        self.models = []
        self._load_models()
    
    def _load_models(self):
        from sentence_transformers import SentenceTransformer
        
        print(f"Cargando {len(self.model_paths)} modelos de embedding en {self.device}:")
        for i, model_path in enumerate(self.model_paths):
            print(f"  {i+1}. {model_path}")
            model = SentenceTransformer(model_path, device=self.device)
            # Optimizar para GPU
            if self.device.type == "cuda":
                model.half()  # Usar FP16 para ahorrar memoria y acelerar
            self.models.append(model)
        print(f"âœ… Todos los modelos cargados en {self.device}")
    
    def rank_by_voting_consensus(self, texts: List[str], labels: List[str]) -> List[Tuple[str, str, float, Dict]]:
        if len(texts) <= 1:
            return [(texts[0], labels[0], 1.0, {})] if texts else []
        
        # Calcular rankings con cada modelo
        all_rankings = []
        model_scores = {}
        
        for i, model in enumerate(self.models):
            model_name = f"model_{i+1}"
            
            # Calcular embeddings y similitudes con batch size optimizado
            batch_size = 64 if self.device.type == "cuda" else 32
            embeddings = model.encode(
                texts, 
                batch_size=batch_size,
                convert_to_numpy=True, 
                normalize_embeddings=True,
                show_progress_bar=False
            )
            sim_matrix = np.dot(embeddings, embeddings.T)
            
            # Calcular scores de consenso
            scores = []
            for j in range(len(texts)):
                other_similarities = [sim_matrix[j][k] for k in range(len(texts)) if j != k]
                avg_similarity = float(np.mean(other_similarities)) if other_similarities else 0.0
                scores.append(avg_similarity)
            
            # Crear ranking para este modelo
            ranked = list(zip(texts, labels, scores))
            ranked.sort(key=lambda x: x[2], reverse=True)
            all_rankings.append(ranked)
            model_scores[model_name] = {labels[j]: scores[j] for j in range(len(labels))}
        
        # VotaciÃ³n por ranking promedio
        final_scores = {}
        voting_details = {}
        
        for label in labels:
            # Obtener posiciÃ³n en cada ranking (1-based)
            positions = []
            individual_scores = []
            
            for ranking in all_rankings:
                for pos, (text, lbl, score) in enumerate(ranking):
                    if lbl == label:
                        positions.append(pos + 1)  # 1-based position
                        individual_scores.append(score)
                        break
            
            # Score final = promedio de scores individuales
            final_score = float(np.mean(individual_scores))
            avg_position = float(np.mean(positions))
            
            final_scores[label] = final_score
            voting_details[label] = {
                "positions": positions,
                "individual_scores": individual_scores,
                "avg_position": avg_position
            }
        
        # Crear ranking final
        final_ranking = []
        for i, label in enumerate(labels):
            text = texts[i]
            score = final_scores[label]
            details = voting_details[label]
            final_ranking.append((text, label, score, details))
        
        # Ordenar por score final
        final_ranking.sort(key=lambda x: x[2], reverse=True)
        
        return final_ranking

def read_jsonl(file_path: Path) -> List[dict]:
    """Lee un archivo JSONL."""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                try:
                    data.append(json.loads(line))
                except json.JSONDecodeError as e:
                    print(f"Error decodificando lÃ­nea: {line[:50]}... Error: {e}")
    return data


def write_jsonl(data: List[dict], file_path: Path):
    """Escribe una lista de diccionarios a un archivo JSONL."""
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')


def load_translated_datasets(base_path: Path, input_field: str = "input") -> Dict[str, List[dict]]:
    """
    Carga todos los datasets traducidos.
    
    Args:
        base_path: Directorio base donde estÃ¡n los datasets
        input_field: Campo que contiene las traducciones
        
    Returns:
        Diccionario {modelo: datos}
    """
    # Patrones de archivos esperados
    patterns = {
        "aina": "*-aina.jsonl", 
        "google": "*-gt.jsonl",
        "nllb": "*-nllb200.jsonl",
        "mbart": "*-mbart.jsonl",
        "opus": "*-opus.jsonl",
        "m2m100": "*-m2m100.jsonl"
    }
    
    datasets = {}
    
    for model_name, pattern in patterns.items():
        files = list(base_path.glob(pattern))
        if files:
            # Tomar el primer archivo que coincida
            file_path = files[0]
            print(f"Cargando {model_name}: {file_path.name}")
            data = read_jsonl(file_path)
            if data:
                datasets[model_name] = data
                print(f"  âœ… {len(data)} elementos cargados")
            else:
                print(f"  âš ï¸  Archivo vacÃ­o")
        else:
            print(f"  âŒ No encontrado patrÃ³n: {pattern}")
    
    return datasets


def align_datasets(datasets: Dict[str, List[dict]], input_field: str = "input") -> List[Dict[str, Any]]:
    """
    Alinea los datasets por Ã­ndice para comparar las mismas preguntas.
    
    Returns:
        Lista de diccionarios con todas las traducciones de cada pregunta
    """
    if not datasets:
        return []
    
    # Obtener el tamaÃ±o mÃ­nimo (en caso de que algunos datasets sean mÃ¡s cortos)
    min_size = min(len(data) for data in datasets.values())
    print(f"Alineando datasets: {min_size} elementos comunes")
    
    aligned_data = []
    
    for i in range(min_size):
        item = {"index": i, "translations": {}, "original": None}
        
        for model_name, data in datasets.items():
            translation = data[i].get(input_field, "")
            item["translations"][model_name] = translation
            
            # Guardar datos originales del primer dataset (para referencia)
            if item["original"] is None:
                original_item = data[i].copy()
                original_item.pop(input_field, None)  # Remover la traducciÃ³n
                item["original"] = original_item
        
        aligned_data.append(item)
    
    return aligned_data


def create_ranked_datasets(aligned_data: List[Dict[str, Any]], 
                          ranker: MultiModelSemanticRanker,
                          top_k_list: List[int] = [2, 3]) -> Tuple[Dict[int, List[dict]], Dict[str, Any]]:    
    """
    Crea datasets rankeados y estadÃ­sticas.
    
    Args:
        aligned_data: Datos alineados de todos los modelos
        ranker: Instancia del rankeador semÃ¡ntico
        top_k_list: Lista de valores k para crear datasets (ej: [2, 3])
        
    Returns:
        Tupla (datasets_rankeados, estadÃ­sticas)
    """
    print(f"ğŸ§® Calculando rankings semÃ¡nticos para {len(aligned_data)} elementos...")
    
    # EstadÃ­sticas
    model_contributions = defaultdict(int)  # CuÃ¡ntas veces cada modelo estÃ¡ en top-k
    model_rankings = defaultdict(list)      # Posiciones de ranking de cada modelo
    similarity_scores = []                  # Todos los scores de similitud
    model_points = defaultdict(int)  # Sistema de puntos acumulativo
    
    # Datasets de salida
    ranked_datasets = {k: [] for k in top_k_list}
    
    for item in tqdm(aligned_data, desc="Procesando rankings"):
        translations = item["translations"]
        
        # Extraer textos y labels
        texts = list(translations.values())
        labels = list(translations.keys())
        
        # Rankear por votaciÃ³n de mÃºltiples modelos
        ranked = ranker.rank_by_voting_consensus(texts, labels)        
        
        # Guardar estadÃ­sticas y asignar puntos
        num_models = len(ranked)
        for i, (text, model, score, voting_details) in enumerate(ranked):
            model_rankings[model].append(i + 1)  # PosiciÃ³n (1-based)
            similarity_scores.append(float(score))
            # Sistema de puntos: 1Âº lugar = 6pts, 2Âº = 5pts, ..., 6Âº = 1pt
            points = num_models - i
            model_points[model] += points
        
        # Crear elementos para cada top-k
        for k in top_k_list:
            top_k_ranked = ranked[:k]
            
            # Contar contribuciones
            for _, model, _, _ in top_k_ranked:
                model_contributions[f"{model}_top{k}"] += 1
            
            # Crear prompt duplicado/triplicado
            top_texts = [text for text, _, _, _ in top_k_ranked]
            
            if k == 2:
                prompt_template = "æˆ‘ç»™ä½ ä¼ é€’é‡å¤çš„æç¤ºï¼Œè¯·æŒ‰ç…§å®ƒä»¬ä¼ è¾¾çš„æŒ‡ä»¤æ“ä½œï¼Œè¿™ä¸¤ä¸ªæ˜¯ç›¸åŒçš„ï¼š{}ï¼Œ{}"
            elif k == 3:
                prompt_template = "æˆ‘ç»™ä½ ä¼ é€’ä¸‰é‡æç¤ºï¼Œè¯·æŒ‰ç…§å®ƒä»¬ä¼ è¾¾çš„æŒ‡ä»¤æ“ä½œï¼Œè¿™ä¸‰ä¸ªæ˜¯ç›¸åŒçš„ï¼š{}ï¼Œ{}ï¼Œ{}"
            else:
                # Para k > 3, formato general
                texts_str = "ï¼Œ".join(top_texts)
                prompt_template = f"æˆ‘ç»™ä½ ä¼ é€’é‡å¤{k}æ¬¡çš„æç¤ºï¼Œè¯·æŒ‰ç…§å®ƒä»¬ä¼ è¾¾çš„æŒ‡ä»¤æ“ä½œï¼Œè¿™äº›éƒ½æ˜¯ç›¸åŒçš„ï¼š{texts_str}"
            
            # Formatear prompt
            if k <= 3:
                formatted_prompt = prompt_template.format(*top_texts)
            else:
                formatted_prompt = prompt_template
            
            # Crear elemento del dataset limpio
            new_item = {
                "input": formatted_prompt,
                "output": item["original"].get("output", "") if item["original"] else ""
            }
            
            ranked_datasets[k].append(new_item)
    
    # Calcular estadÃ­sticas finales
    stats = {
        "total_questions": len(aligned_data),
        "models_analyzed": list(set(model_rankings.keys())),
        "model_total_points": dict(model_points),
        "model_avg_points": {
            model: float(total_points / len(aligned_data)) for model, total_points in model_points.items()
        },
        "model_avg_ranking": {
            model: float(np.mean(rankings)) for model, rankings in model_rankings.items()
        },
        "model_contributions_by_topk": dict(model_contributions),
        "ranking_distribution": {
            model: {f"pos_{i+1}": rankings.count(i+1) for i in range(6)}
            for model, rankings in model_rankings.items()
        },
        "overall_similarity_stats": {
            "mean": float(np.mean(similarity_scores)),
            "std": float(np.std(similarity_scores)),
            "min": float(np.min(similarity_scores)),
            "max": float(np.max(similarity_scores))
        }
    }
    
    return ranked_datasets, stats


def print_statistics(stats: Dict[str, Any]):
    """Imprime estadÃ­sticas de manera legible."""
    print("\n" + "="*60)
    print("ğŸ“Š ESTADÃSTICAS DE RANKING SEMÃNTICO")
    print("="*60)
    
    print(f"\nğŸ“ˆ Resumen general:")
    print(f"  Total de preguntas analizadas: {stats['total_questions']}")
    print(f"  Modelos analizados: {', '.join(stats['models_analyzed'])}")
    
    print(f"\nğŸ† Ranking promedio por modelo (menor = mejor):")
    for model, avg_rank in sorted(stats['model_avg_ranking'].items(), key=lambda x: x[1]):
        print(f"  {model:12} â†’ {avg_rank:.2f}")
    
    print(f"\nğŸ¯ Puntos totales por modelo (mayor = mejor):")
    for model, points in sorted(stats['model_total_points'].items(), key=lambda x: x[1], reverse=True):
        avg_points = stats['model_avg_points'][model]
        print(f"  {model:12} â†’ {points:4d} pts (avg: {avg_points:.2f})")
    
    print(f"\nğŸ“Š DistribuciÃ³n de posiciones:")
    for model in sorted(stats['ranking_distribution'].keys()):
        dist = stats['ranking_distribution'][model]
        dist_str = " ".join([f"{pos}:{count}" for pos, count in dist.items() if count > 0])
        print(f"  {model:12} â†’ {dist_str}")
    
    print(f"\nğŸ“Š Contribuciones por TOP-K:")
    contributions = stats['model_contributions_by_topk']
    
    # Agrupar por top-k
    top_k_groups = defaultdict(dict)
    for key, count in contributions.items():
        if '_top' in key:
            model, top_k = key.rsplit('_top', 1)
            top_k_groups[top_k][model] = count
    
    for top_k, models in sorted(top_k_groups.items()):
        print(f"\n  TOP-{top_k}:")
        total = sum(models.values())
        for model, count in sorted(models.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total) * 100 if total > 0 else 0
            print(f"    {model:12} â†’ {count:4d} ({percentage:5.1f}%)")
    
    print(f"\nğŸ“Š EstadÃ­sticas de similitud:")
    sim_stats = stats['overall_similarity_stats']
    print(f"  Media: {sim_stats['mean']:.4f}")
    print(f"  Desv. estÃ¡ndar: {sim_stats['std']:.4f}")
    print(f"  Rango: [{sim_stats['min']:.4f}, {sim_stats['max']:.4f}]")


def main():
    parser = argparse.ArgumentParser(
        description="Crea datasets con ranking semÃ¡ntico de traducciones"
    )
    
    # ConfiguraciÃ³n de entrada
    parser.add_argument("--data_dir", type=str, default=".",
                       help="Directorio donde estÃ¡n los datasets traducidos")
    parser.add_argument("--input_field", type=str, default="input",
                       help="Campo que contiene las traducciones")
    
    # ConfiguraciÃ³n del modelo de embeddings
    parser.add_argument("--embedding_models", type=str, nargs=3, 
                   default=["sentence-transformers/LaBSE", "BAAI/bge-large-zh-v1.5", "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"],
                   help="3 modelos de embeddings para votaciÃ³n")
    parser.add_argument("--device", type=str, default="auto",
                       choices=["auto", "cuda", "cpu"],
                       help="Dispositivo para embeddings")
    
    # ConfiguraciÃ³n de salida
    parser.add_argument("--output_dir", type=str, default="./ranked_datasets",
                       help="Directorio de salida")
    parser.add_argument("--top_k", type=int, nargs="+", default=[2, 3],
                       help="Valores de k para crear datasets (ej: --top_k 2 3)")
    
    # ParÃ¡metros adicionales
    parser.add_argument("--batch_size", type=int, default=32,
                       help="Batch size para cÃ¡lculo de embeddings")
    
    args = parser.parse_args()
    
    # Configurar paths
    data_dir = Path(args.data_dir)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("="*60)
    print("ğŸš€ INICIANDO RANKING SEMÃNTICO DE TRADUCCIONES")
    print("="*60)
    # Mostrar info de GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸ® GPU detectada: {gpu_name} ({gpu_memory:.1f}GB)")
    else:
        print("ğŸ’» Usando CPU")
    print(f"ğŸ“ Directorio de datos: {data_dir}")
    print(f"ğŸ“ Directorio de salida: {output_dir}")
    print(f"ğŸ¤– Modelos de embeddings: {args.embedding_models}")
    print(f"ğŸ“Š TOP-K valores: {args.top_k}")
    print("="*60)
    
    try:
        # 1. Cargar modelo de embeddings
        print("\n1ï¸âƒ£ Cargando modelos de embeddings...")
        ranker = MultiModelSemanticRanker(
            model_paths=args.embedding_models,
            device=args.device
        )
        
        # 2. Cargar todos los datasets traducidos
        print("\n2ï¸âƒ£ Cargando datasets traducidos...")
        datasets = load_translated_datasets(data_dir, args.input_field)
        
        if not datasets:
            raise ValueError("No se encontraron datasets traducidos")
        
        print(f"âœ… Cargados {len(datasets)} datasets: {list(datasets.keys())}")
        
        # 3. Alinear datasets
        print("\n3ï¸âƒ£ Alineando datasets...")
        aligned_data = align_datasets(datasets, args.input_field)
        
        if not aligned_data:
            raise ValueError("No se pudieron alinear los datasets")
        
        # 4. Crear rankings y datasets
        print("\n4ï¸âƒ£ Creando rankings semÃ¡nticos...")
        ranked_datasets, stats = create_ranked_datasets(
            aligned_data, ranker, args.top_k
        )
        
        # 5. Guardar datasets rankeados
        print("\n5ï¸âƒ£ Guardando datasets rankeados...")
        for k, dataset in ranked_datasets.items():
            output_path = output_dir / f"top{k}_ranked_dataset.jsonl"
            write_jsonl(dataset, output_path)
            print(f"  âœ… TOP-{k}: {len(dataset)} elementos â†’ {output_path}")
        
        # 6. Guardar estadÃ­sticas
        stats_path = output_dir / "ranking_statistics.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        print(f"  âœ… EstadÃ­sticas â†’ {stats_path}")
        
        # 7. Mostrar estadÃ­sticas
        print_statistics(stats)
        
        print(f"\nâœ… Â¡Proceso completado exitosamente!")
        print(f"ğŸ“ Resultados guardados en: {output_dir}")
        
    except Exception as e:
        print(f"\nâŒ Error durante el procesamiento: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()